{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:nb]",
      "language": "python",
      "name": "conda-env-nb-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "01-getting_started.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZjOrKRnq5aa"
      },
      "source": [
        "# Getting started with Nobrainer\n",
        "\n",
        "Nobrainer is a deep learning framework for 3D image processing. It implements several 3D convolutional models from recent literature, methods for loading and augmenting volumetric data than can be used with any TensorFlow or Keras model, losses and metrics for 3D data, and utilities for model training, evaluation, prediction, and transfer learning.\n",
        "\n",
        "The code for the Nobrainer framework is available on GitHub at https://github.com/neuronets/nobrainer. The Nobrainer project is supported by NIH R01 EB020470 and is distributed under the Apache 2.0 license.\n",
        "\n",
        "## Questions or issues\n",
        "\n",
        "If you have questions about Nobrainer or encounter any issues using the framework, please [submit a GitHub issue](https://github.com/neuronets/nobrainer/issues/new). If you have a feature request, we encourage you to submit a pull request."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwaWX82pq5ad"
      },
      "source": [
        "# Using the guide notebooks\n",
        "\n",
        "Please install `nobrainer` before using these notebooks. You can learn how to do this below. Most of the notebooks also require some data on which to train or evaluate. You can use your own data, but `nobrainer` also provides a utility to download a small public dataset. Please refer to the notebook `02-preparing_training_data.ipynb` to download and prepare the example data for use or to prepare your own data for use.\n",
        "\n",
        "After you have gone through `02-preparing_training_data.ipynb`, please take a look at the other notebooks in this guide.\n",
        "\n",
        "## Google Colaboratory\n",
        "\n",
        "These notebooks can be [run for free](https://colab.research.google.com/github/neuronets/nobrainer) on Google Colaboratory (you must be signed into a Google account). If you are using Colab, please note that multiple open tabs of Colab notebooks will use the same resources (RAM, GPU). Downloading data in multiple Colab notebooks at the same time or training multiple models can quickly exhaust the available resources. For this reason, please run one notebook at a time, and keep an eye on the resources used.\n",
        "\n",
        "Users can choose to run Colab notebooks on CPU, GPU, or TPU. By default, the notebooks will use the CPU runtime. To use a different runtime, please select `Runtime > Change runtime type` in the menu bar. Then, choose either `GPU` or `TPU` under `Hardware accelerator`. No code changes are required when running on CPU or GPU runtime. When using the TPU runtime, however, special care must be taken for things to work properly. Please refer to the TPU guide notebook in this directory for more information.\n",
        "\n",
        "## Jupyter Notebook\n",
        "\n",
        "These notebooks can use whatever hardware you have available, whether it is CPU, GPU, or TPU. Please note that training models on CPU can take a very long time. GPUs will greatly increase speed of training and inference. Some of the notebooks download example data, but you can feel free to use your own data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fO5RSFbq5ad"
      },
      "source": [
        "# Install Nobrainer\n",
        "\n",
        "Nobrainer can be installed using `pip`. Use the extra `[gpu]` to install TensorFlow with GPU support or the extra `[cpu]` to install TensorFlow without GPU support. If you intend to train models, you should use GPU-enabled TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xELN1Hcq5ae",
        "outputId": "693688c0-12e5-43f2-d986-49062b754ff9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install --no-cache-dir nobrainer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nobrainer\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/a4/2df3134950582614be767cb88c8d845d931b6d2eff47b1041e335f6fc142/nobrainer-0.0.3-py3-none-any.whl (66kB)\n",
            "\r\u001b[K     |█████                           | 10kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 20kB 20.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 30kB 16.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 40kB 14.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 51kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 61kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-probability>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from nobrainer) (0.12.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nobrainer) (7.1.2)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from nobrainer) (3.0.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from nobrainer) (0.16.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nobrainer) (1.19.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.7.0->nobrainer) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.7.0->nobrainer) (1.3.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.7.0->nobrainer) (0.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.7.0->nobrainer) (1.15.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.7.0->nobrainer) (0.1.6)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->nobrainer) (1.1.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->nobrainer) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->nobrainer) (2.5.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->nobrainer) (7.1.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->nobrainer) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->nobrainer) (2.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->nobrainer) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->nobrainer) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->nobrainer) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->nobrainer) (2.4.7)\n",
            "Installing collected packages: nobrainer\n",
            "Successfully installed nobrainer-0.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVMXci7Mq5ae"
      },
      "source": [
        "# Accessing Nobrainer\n",
        "\n",
        "## Command-line\n",
        "\n",
        "Nobrainer provides the command-line program `nobrainer`, which contains various methods for preparing data, training and evaluating models, generating predictions, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU6edUxDq5af",
        "outputId": "e49a01f8-32ec-42aa-c658-d58be6c40969",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nobrainer --help"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-11 15:51:56.445105: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Usage: nobrainer [OPTIONS] COMMAND [ARGS]...\n",
            "\n",
            "  A framework for developing neural network\n",
            "  models for 3D image processing.\n",
            "\n",
            "Options:\n",
            "  --version  Show the version and exit.\n",
            "  --help     Show this message and exit.\n",
            "\n",
            "Commands:\n",
            "  convert   Convert medical imaging volumes to...\n",
            "  evaluate  Evaluate a model's predictions...\n",
            "  info      Return information about this...\n",
            "  merge     Merge multiple models trained with...\n",
            "  predict   Predict labels from features using\n",
            "            a...\n",
            "\n",
            "  save      Save a model to SavedModel type.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP6dWeNXq5af"
      },
      "source": [
        "## Python\n",
        "\n",
        "The `nobrainer` Python package can be imported as below. This gives you access to all of nobrainer's modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8mYOLaWq5af"
      },
      "source": [
        "import nobrainer"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKpEQi0Xq5ag"
      },
      "source": [
        "### Layout\n",
        "\n",
        "- `nobrainer.io`: input/output methods\n",
        "- `nobrainer.layers`: custom Keras layers\n",
        "- `nobrainer.losses`: loss functions for volumetric segmentation\n",
        "- `nobrainer.metrics`: metrics for volumetric segmentation\n",
        "- `nobrainer.models`: pre-defined Keras models\n",
        "- `nobrainer.tfrecords`: writing and reading of TFRecords files\n",
        "- `nobrainer.transform`: rigid transformations for data augmentation\n",
        "- `nobrainer.volume`: `tf.data.Dataset` creation and data augmentation utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG0lFj2gq5ag"
      },
      "source": [
        "# Next steps\n",
        "\n",
        "Here are other Jupyter notebooks in this guide to learn how to prepare your training data, train models on different hardware (single GPU, multiple GPUs, or TPU), and more. These tutorial notebooks will be updated and enhanced regularly. If you think something is missing or could be improved, please [submit a GitHub issue](https://github.com/neuronets/helpdesk/issues/new/choose).\n",
        "\n",
        "## Tutorials:\n",
        "\n",
        "- [Preparing training data](https://colab.research.google.com/github/neuronets/nobrainer/blob/master/guide/02-preparing_training_data.ipynb)\n",
        "- [Train binary classification](https://colab.research.google.com/github/neuronets/nobrainer/blob/master/guide/train_binary_classification.ipynb)\n",
        "- [Train binary segmentation](https://colab.research.google.com/github/neuronets/nobrainer/blob/master/guide/train_binary_segmentation.ipynb)\n",
        "- [Train on multiple GPUs](https://colab.research.google.com/github/neuronets/nobrainer/blob/master/guide/train_on_multiple_gpus.ipynb)\n",
        "- [Train on a TPU](https://colab.research.google.com/github/neuronets/nobrainer/blob/master/guide/train_on_tpu.ipynb)\n",
        "- [Transfer learning example](https://colab.research.google.com/github/neuronets/nobrainer/blob/master/guide/transfer_learning.ipynb)"
      ]
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlHhhplL7opm"
   },
   "source": [
    "# Train a neural network for mri generation using progressive growing\n",
    "\n",
    "In this notebook, we will use Nobrainer to train a model for brain MRI generation. Brain MRI generation is a useful task in synthetically creating neuroimaging data. We will use a Generative Adversarial Network to model the generation and use a progressive growing training method for high quality generation at higher resolutions.\n",
    "\n",
    "In the following cells, we will:\n",
    "\n",
    "1. Get sample T1-weighted MR scans as features.\n",
    "2. Convert the data to TFRecords format.\n",
    "3. Instantiate a progressive convolutional neural network for generator and discriminator.\n",
    "4. Create a Dataset of the features.\n",
    "5. Instantiate a trainer and choose a loss function to use.\n",
    "6. Train on part of the data in two phases (transition and resolution).\n",
    "7. Repeat steps 4-6 for each growing resolution.\n",
    "8. Generate some images using trained model\n",
    "\n",
    "## Google Colaboratory\n",
    "\n",
    "If you are using Colab, please switch your runtime to GPU. To do this, select `Runtime > Change runtime type` in the top menu. Then select GPU under `Hardware accelerator`. A GPU greatly speeds up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUwl5vYH7rrD"
   },
   "outputs": [],
   "source": [
    "!pip install --no-cache-dir nilearn https://github.com/neuronets/nobrainer/archive/refs/heads/enh/api.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qpm8u9O47opq"
   },
   "outputs": [],
   "source": [
    "import nobrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAl3sk8e7opr"
   },
   "source": [
    "# Get sample features and labels\n",
    "\n",
    "We use 9 pairs of volumes for training and 1 pair of volumes for evaluation. Many more volumes would be required to train a model for any useful purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yV9F64HE7opr"
   },
   "outputs": [],
   "source": [
    "csv_of_filepaths = nobrainer.utils.get_data()\n",
    "filepaths = nobrainer.io.read_csv(csv_of_filepaths)\n",
    "\n",
    "train_paths = filepaths[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqzlAmyI7ops"
   },
   "source": [
    "# Convert medical images to TFRecords\n",
    "\n",
    "Remember how many full volumes are in the TFRecords files. This will be necessary to know how many steps are in on training epoch. The default training method needs to know this number, because Datasets don't always know how many items they contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nobrainer.dataset import write_multi_resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = write_multi_resolution(train_paths, \n",
    "                                  tfrecdir=\"data/generate\",\n",
    "                                  n_processes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets will look like the following. One can adjust the batch size depending on compute power.\n",
    "\n",
    "```python\n",
    "datasets = {8: {'file_pattern': '/home/jovyan/temp/nobrainer/guide/data/*res-008.tfrec',\n",
    "  'batch_size': 1,\n",
    "  'normalizer': None},\n",
    " 16: {'file_pattern': '/home/jovyan/temp/nobrainer/guide/data/*res-016.tfrec',\n",
    "  'batch_size': 1,\n",
    "  'normalizer': None},\n",
    " 32: {'file_pattern': '/home/jovyan/temp/nobrainer/guide/data/*res-032.tfrec',\n",
    "  'batch_size': 1,\n",
    "  'normalizer': None},\n",
    " 64: {'file_pattern': '/home/jovyan/temp/nobrainer/guide/data/*res-064.tfrec',\n",
    "  'batch_size': 1,\n",
    "  'normalizer': None},\n",
    " 128: {'file_pattern': '/home/jovyan/temp/nobrainer/guide/data/*res-128.tfrec',\n",
    "  'batch_size': 1,\n",
    "  'normalizer': None},\n",
    " 256: {'file_pattern': '/home/jovyan/temp/nobrainer/guide/data/*res-256.tfrec',\n",
    "  'batch_size': 1,\n",
    "  'normalizer': None}}\n",
    "```\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "datasets[8][\"batch_size\"] = 32\n",
    "datasets[16][\"batch_size\"] = 16\n",
    "datasets[32][\"batch_size\"] = 8\n",
    "datasets[64][\"batch_size\"] = 4\n",
    "datasets[128][\"batch_size\"] = 1\n",
    "datasets[256][\"batch_size\"] = 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nobrainer.processing.generation import ProgressiveGeneration\n",
    "gen = ProgressiveGeneration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.fit(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "img = gen.generate()\n",
    "plotting.plot_anat(anat_img=img, draw_cross=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can warm start the training, but for the moment it will only retrain using the final resolution of the data or higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.fit(datasets, warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "img = gen.generate()\n",
    "plotting.plot_anat(anat_img=img, draw_cross=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "train_generation_progressive.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
